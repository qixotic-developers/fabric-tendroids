= Performance Analysis & Next Steps
:toc: left
:icons: font

== Current State

*Performance Improvement Achieved:* 17fps → 24fps (43% improvement)

Results with 30 Tendroids:
- Average: 24.31 fps
- Min: 18.43 fps  
- Max: 32.04 fps (sometimes >50fps!)

The optimization *worked* but we're not consistently hitting the 50fps baseline yet.

== What We Fixed

Eliminated Python list comprehension bottleneck in vertex data conversion:

*Before:*
[source,python]
----
# GPU → CPU → Python list of Gf.Vec3f → Vt.Vec3fArray
deformed_data = self.deformed_positions.numpy()
return [Gf.Vec3f(float(v[0]), float(v[1]), float(v[2])) for v in deformed_data]
----

*After:*
[source,python]
----
# GPU → CPU → Vt.Vec3fArray (zero-copy)
deformed_data = self.deformed_positions.numpy()
return Vt.Vec3fArray.FromBuffer(deformed_data)
----

*Speedup:* Eliminated ~100ms per frame overhead for 30 Tendroids.

== Remaining Performance Gap

*Target:* 50fps with 15-30 Tendroids
*Current:* 37fps @ 15, 24fps @ 30

*Missing ~10-25fps* - Where is it going?

=== Hypothesis 1: Terrain Conforming

Every Tendroid creation log shows:
----
[TerrainConform] Conforming 3 base segments to terrain
[TerrainConform] Base height range: [-4.60, -3.96]
----

This modifies vertices at creation time. *If this is being done per-frame*, it could be expensive.

=== Hypothesis 2: GPU→CPU Transfer

`self.deformed_positions.numpy()` still does a GPU→CPU memory transfer every frame.

*Per Tendroid:*
- 272 vertices × 12 bytes (3 floats) = 3.3KB
- 30 Tendroids = 99KB per frame
- At 60fps = 6MB/sec bandwidth

This isn't huge, but PCIe latency adds up. Each transfer has ~0.1-0.5ms overhead.

=== Hypothesis 3: USD Write Performance

Even with optimized data, `points_attr.Set(vertices)` still goes through USD's change notification system.

30 mesh updates per frame could be triggering USD invalidation/tracking overhead.

=== Hypothesis 4: Warp Kernel Launch Overhead

Each Tendroid calls `wp.launch()` individually. Potential 30 kernel launches per frame.

*Better:* Batch all Tendroids into one large kernel launch.

== Profiling Tools Created

Three new tools to identify the bottleneck:

=== 1. diagnose_performance.py
Tests data conversion overhead in isolation.

[source,python]
----
from qixotic.tendroids import diagnose_performance
diagnose_performance.profile_data_conversion()
----

=== 2. utils/profiler.py
Frame-by-frame timing instrumentation.

=== 3. test_profiled.py  
Run animation with profiling enabled.

[source,python]
----
from qixotic.tendroids import test_profiled
test_profiled.run_profiled_test_sync(30, 5.0)
----

This will show per-frame timing breakdown.

== Next Steps

=== Step 1: Run Profiled Test

*NO RESTART NEEDED* - Python code is hot-reloadable.

In Script Editor:
[source,python]
----
from qixotic.tendroids import test_profiled
test_profiled.run_profiled_test_sync(30, 5.0)
----

Look for the profile report at the end showing:
----
Performance Profile Report
Checkpoint                    Avg (ms)     Min (ms)     Max (ms)
----------------------------------------------------------------------
TOTAL_FRAME                   41.2         30.5         55.8
UPDATE_ALL_TENDROIDS          38.1         28.2         52.1
TENDROID_00_UPDATE            1.3          0.9          2.1
...
----

This will tell us where the time is going.

=== Step 2: Based on Results

*If most time is in TENDROID_XX_UPDATE:*
→ The per-Tendroid update is the bottleneck
→ Need to batch Warp kernel launches

*If most time is in UPDATE_ALL_TENDROIDS but not in individual updates:*
→ The loop overhead or USD updates are slow
→ Consider batching USD writes

*If TOTAL_FRAME >> UPDATE_ALL_TENDROIDS:*
→ Something else in the frame is expensive
→ Check what's happening outside animation updates

=== Step 3: Targeted Optimization

Based on Step 2 results, we can:

*Option A: Batch Warp Kernels*
Launch one kernel for all 30 Tendroids instead of 30 separate launches.

*Option B: Batch USD Updates*
Collect all vertex updates and write in one transaction.

*Option C: Reduce Per-Frame Work*
Cache more, compute less, update selectively.

== Configuration Check

*Current Settings:*
- num_segments: 16 (vertical resolution)
- radial_resolution: 16 (circumference)
- Total vertices per Tendroid: 272

*Config file says:* radial_resolution should be 32, but code uses 16.

*This is actually GOOD* - fewer vertices = better performance.

If you want to match the "original" config:
[source,python]
----
# In tendroid_factory.py, add radial_resolution parameter
tendroid = Tendroid(
    ...
    radial_resolution=get_config_value("tendroid_geometry", "radial_resolution", default=16)
)
----

But I'd recommend keeping it at 16 for now.

== Files Modified This Session

[cols="2,3"]
|===
|File |Purpose

|`core/warp_deformer.py`
|OPTIMIZED: Returns Vt.Vec3fArray directly

|`core/mesh_updater.py`
|OPTIMIZED: Accepts Vt.Vec3fArray directly

|`diagnose_performance.py`
|NEW: Data conversion benchmark

|`utils/profiler.py`
|NEW: Frame-by-frame timing instrumentation

|`scene/animation_controller.py`
|INSTRUMENTED: Added profiling checkpoints

|`test_profiled.py`
|NEW: Profiled test runner

|`OPTIMIZATION_SUMMARY.adoc`
|DOCUMENTATION: First optimization pass

|`PERFORMANCE_ANALYSIS.adoc`
|DOCUMENTATION: This file - next steps
|===

== Summary

We've achieved a 43% performance improvement, but there's still a 10-25fps gap to the target.

*Run the profiled test to identify the next bottleneck*, then we can apply targeted optimization.

The good news: You're seeing *peaks above 50fps*, which means the theoretical performance is there - we just need to make it consistent.

'''
*Status:* Ready for profiling
*Last Updated:* 2025-11-15
